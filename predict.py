import torch
from transformers import AutoTokenizer
from model import EmotionClassifier

project_path = '/content/drive/MyDrive/emotion_project'

reverse_label_mapping = {
    0: "ê³µí¬", 1: "ë†€ëŒ", 2: "ë¶„ë…¸",
    3: "ìŠ¬í””", 4: "ì¤‘ë¦½", 5: "í–‰ë³µ", 6: "í˜ì˜¤"
}

emoji_dict = {
    0: ["ğŸ˜±", "ğŸ˜¨", "ğŸ‘»"],       # ê³µí¬
    1: ["ğŸ˜²", "ğŸ˜¯", "ğŸ˜³"],       # ë†€ëŒ
    2: ["ğŸ˜¡", "ğŸ˜ ", "ğŸ¤¬"],       # ë¶„ë…¸
    3: ["ğŸ˜­", "ğŸ˜¢", "ğŸ˜"],       # ìŠ¬í””
    4: ["ğŸ˜", "ğŸ˜‘", "ğŸ™‚"],       # ì¤‘ë¦½
    5: ["ğŸ˜„", "ğŸ˜‚", "ğŸ˜"],       # í–‰ë³µ
    6: ["ğŸ¤¢", "ğŸ¤®", "ğŸ˜–"]        # í˜ì˜¤
}

def predict_conversation(window_size=3):
    """ìŠ¬ë¼ì´ë”© ìœˆë„ìš° ëŒ€í™” ì˜ˆì¸¡"""
    pretrained_model_name = "klue/bert-base"
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    tokenizer = AutoTokenizer.from_pretrained(pretrained_model_name)

    model = EmotionClassifier(pretrained_model_name, num_classes=7).to(device)
    model.load_state_dict(torch.load(f"{project_path}/model.pth", map_location=device))
    model.eval()

    print(f"ğŸ—£ï¸ ëŒ€í™” ì‹œì‘! (ìœˆë„ìš° í¬ê¸°: {window_size}, ì¢…ë£Œ: exit)")
    conversation = []

    while True:
        user_input = input("ğŸ’¬ ì…ë ¥: ").strip()
        if user_input.lower() == "exit":
            break
        
        conversation.append(user_input)
        
        # ìŠ¬ë¼ì´ë”© ìœˆë„ìš°ë¡œ ì…ë ¥ êµ¬ì„±
        window = conversation[-window_size:] if len(conversation) >= window_size else conversation
        
        if len(window) == 1:
            full_text = window[0]
        else:
            full_text = " [SEP] ".join(window)
            print(f"ğŸ“– ë¬¸ë§¥: {' â†’ '.join(window[:-1])}")
        
        # ì˜ˆì¸¡
        inputs = tokenizer(full_text, return_tensors='pt', truncation=True, padding='max_length', max_length=128)
        input_ids = inputs['input_ids'].to(device)
        attention_mask = inputs['attention_mask'].to(device)

        with torch.no_grad():
            outputs = model(input_ids, attention_mask)
            probs = torch.sigmoid(outputs).squeeze().cpu().numpy()

        # ìƒìœ„ 2ê°œ ê°ì •
        indexed = list(enumerate(probs))
        top2 = sorted(indexed, key=lambda x: x[1], reverse=True)[:2]

        first_idx, first_score = top2[0]
        second_idx, second_score = top2[1]
        
        label1 = reverse_label_mapping[first_idx]
        label2 = reverse_label_mapping[second_idx]
        
        print(f"ğŸ¯ ê°ì •: {label1} ({first_score:.3f}), {label2} ({second_score:.3f})")

        # ì´ëª¨ì§€ ì¶”ì²œ
        emoji_list1 = emoji_dict.get(first_idx, ["â“"])
        emoji_list2 = emoji_dict.get(second_idx, ["â“"])
        
        if second_score >= 0.5:
            emojis = emoji_list1[:2] + [emoji_list2[0]]
        else:
            emojis = emoji_list1[:3]

        print(f"ğŸ¨ ì¶”ì²œ ì´ëª¨ì§€: {' '.join(emojis)}\n")

def predict_single():
    """ë‹¨ì¼ ë¬¸ì¥ ì˜ˆì¸¡ (ê¸°ì¡´ ë°©ì‹)"""
    pretrained_model_name = "klue/bert-base"
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    tokenizer = AutoTokenizer.from_pretrained(pretrained_model_name)

    model = EmotionClassifier(pretrained_model_name, num_classes=7).to(device)
    model.load_state_dict(torch.load(f"{project_path}/model.pth", map_location=device))
    model.eval()

    while True:
        text = input("ë¬¸ì¥ ì…ë ¥ (ì¢…ë£Œ: exit): ").strip()
        if text.lower() == "exit":
            break
        
        inputs = tokenizer(text, return_tensors='pt', truncation=True, padding='max_length', max_length=128)
        input_ids = inputs['input_ids'].to(device)
        attention_mask = inputs['attention_mask'].to(device)

        with torch.no_grad():
            outputs = model(input_ids, attention_mask)
            probs = torch.sigmoid(outputs).squeeze().cpu().numpy()

        indexed = list(enumerate(probs))
        top2 = sorted(indexed, key=lambda x: x[1], reverse=True)[:2]

        first_idx, first_score = top2[0]
        second_idx, second_score = top2[1]

        label1 = reverse_label_mapping[first_idx]
        label2 = reverse_label_mapping[second_idx]
        emoji_list1 = emoji_dict.get(first_idx, ["â“"])
        emoji_list2 = emoji_dict.get(second_idx, ["â“"])

        print(f"ê°ì •: {label1} ({first_score:.2f}), {label2} ({second_score:.2f})")

        if second_score >= 0.5:
            emojis = emoji_list1[:2] + [emoji_list2[0]]
        else:
            emojis = emoji_list1[:3]

        print(f"ì´ëª¨ì§€: {' '.join(emojis)}\n")

if __name__ == "__main__":
    print("ëª¨ë“œ ì„ íƒ:")
    print("1. ëŒ€í™” ëª¨ë“œ (ìŠ¬ë¼ì´ë”© ìœˆë„ìš°)")
    print("2. ë‹¨ì¼ ë¬¸ì¥ ëª¨ë“œ")
    
    choice = input("ì„ íƒ (1/2): ").strip()
    
    if choice == "1":
        predict_conversation()
    else:
        predict_single()